# ü¶ô Ollama

>[!INFO] LM Studio –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Å–µ–±—è —Å—Ç–∞–±–∏–ª—å–Ω–µ–µ –≤ —Ä–∞–±–æ—Ç–µ

## ‚¨áÔ∏è Install on linux

```shell
curl -fsSL https://ollama.com/install.sh | sh
```

## ü§ñ Get LLM

```shell
ollama pull *Model_name*
```

>[!INFO] `Model_name` - –≠—Ç–æ –Ω–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏, –¥–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–∂–Ω–æ –Ω–∞–π—Ç–∏ –Ω–∞ [Ollama Library](https://ollama.com/library)

## üèÉ Run LLM

```shell
ollama pull *Model_name*
```

>[!INFO] `Model_name` - –≠—Ç–æ –Ω–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏, –¥–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–∂–Ω–æ –Ω–∞–π—Ç–∏ –Ω–∞ [Ollama Library](https://ollama.com/library)

---

# üì¶ LM Studio

## ‚¨áÔ∏è Install

–°–∫–∞—á–∞—Ç—å –ø–∞–∫–µ—Ç –ø–æ–¥ —Å–≤–æ—é —Å–∏—Å—Ç–µ–º—É –Ω–∞ [LM Studio Website](https://lmstudio.ai)

## ü§ñ Get LLM

–í–æ –≤–∫–ª–∞–¥–∫–µ Discover –º–æ–∂–Ω–æ –Ω–∞–π—Ç–∏ –∏ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å —Ç—Ä–µ–±—É–µ–º—É—é –º–æ–¥–µ–ª—å

## üèÉ Run LLM

–î–ª—è –∑–∞–ø—É—Å–∫–∞ –ø–µ—Ä–µ–π—Ç–∏ –≤–æ –≤–∫–ª–∞–¥–∫—É Developer, –ù–∞–∂–∞—Ç—å Run Server, –í—ã–±—Ä–∞—Ç—å –º–æ–¥–µ–ª—å –≤ Select model to load

---

# ‚è© Continue plugin for IDE

–£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å Continue –ø–ª–∞–≥–∏–Ω –¥–ª—è vscode –∏–ª–∏ jetbrains

–ü–µ—Ä–µ–π—Ç–∏ –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –ø–ª–∞–≥–∏–Ω–∞

## ü¶ô Ollama configuration

–ü—Ä–∏–º–µ—Ä –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏:

```json
{
  "models": [
    {
      "apiBase": "http://localhost:11434/",
      "model": "codellama",
      "provider": "ollama",
      "title": "CodeLlama"
    }
  ],
  "tabAutocompleteModel": {
    "title": "Starcoder2 3b",
    "provider": "ollama",
    "model": "starcoder2:3b"
  },
  "tabAutocompleteOptions": {
    "debounceDelay": 500,
    "maxPromptTokens": 100
  },
...
```

## üì¶ LM Studio configuration

–ü—Ä–∏–º–µ—Ä –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏:

```json
{
  "models": [
    {
      "apiBase": "http://localhost:1234/v1",
      "model": "autodetect",
      "provider": "lmstudio",
      "title": "codestral"
    }
  ],
  "tabAutocompleteModel": {
    "title": "codestral",
    "provider": "lmstudio",
    "model": "autodetect",
    "apiBase": "http://localhost:1234/v1"
  },
  "tabAutocompleteOptions": {
    "debounceDelay": 500,
    "maxPromptTokens": 100
  },
  ...
```

---

# üåé Links

- [Ollama website](https://ollama.com)
- [Ollama Library](https://ollama.com/library)
- [LM Studio Website](https://lmstudio.ai)
- [Continue plugin](https://marketplace.visualstudio.com/items?itemName=Continue.continue)
- [Add ollama in vscode guide by dev.to](https://dev.to/manjushsh/configuring-ollama-and-continue-vs-code-extension-for-local-coding-assistant-48li)

---
